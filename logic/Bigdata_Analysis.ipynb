{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqxel0pQx0/fMo1DXTOtSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Method-for-Software-System-Development/Cloud_Computing/blob/develop/logic/Bigdata_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gZUwyuSyArIs",
        "outputId": "741464f3-3512-4f18-db6b-4ac28669b365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25homer_cohen 050-111-2222 200\n",
            "shira_gold 050-222-3333 200\n",
            "daniel_bar 050-333-4444 200\n",
            "roni_benami 050-444-5555 200\n",
            "lior_levi 050-555-6666 200\n",
            "yael_elyashiv 050-666-7777 200\n",
            "noa_katz 050-777-8888 200\n",
            "matan_tal 050-888-9999 200\n",
            "or_peled 050-999-0000 200\n",
            "tom_segal 050-000-1111 200\n",
            "Daniel Bar | 050-333-4444 | Robotics Engineer\n",
            "Lior Levi | 050-555-6666 | Backend Developer\n",
            "Matan Tal | 050-888-9999 | Mechanical Engineer\n",
            "Noa Katz | 050-777-8888 | UX Designer\n",
            "Omer Cohen | 050-111-2222 | Automation Engineer\n",
            "Or Peled | 050-999-0000 | System Engineer\n",
            "Roni Ben Ami | 050-444-5555 | QA Engineer\n",
            "Shira Gold | 050-222-3333 | Electrical Engineer\n",
            "Tom Segal | 050-000-1111 | Production Engineer\n",
            "Yael Elyashiv | 050-666-7777 | Hardware Engineer\n",
            "Indoor Sensor Data:\n",
            "Status: 200 | Uploaded: {'Temperature': 26.4, 'Humidity': 41.0, 'Pressure': 974.1, 'Distance': 210.1}\n",
            "Status: 200 | Uploaded: {'Temperature': 36.5, 'Humidity': 91.3, 'Pressure': 919.8, 'Distance': 12.2}\n",
            "Status: 200 | Uploaded: {'Temperature': 27.1, 'Humidity': 73.0, 'Pressure': 1050.4, 'Distance': 205.0}\n",
            "Status: 200 | Uploaded: {'Temperature': 25.8, 'Humidity': 45.2, 'Pressure': 960.0, 'Distance': 210.0}\n",
            "Status: 200 | Uploaded: {'Temperature': 28.9, 'Humidity': 89.9, 'Pressure': 950.6, 'Distance': 250.0}\n",
            "Status: 200 | Uploaded: {'Temperature': 35.1, 'Humidity': 93.0, 'Pressure': 1082.3, 'Distance': 10.1}\n",
            "Status: 200 | Uploaded: {'Temperature': 29.4, 'Humidity': 55.6, 'Pressure': 1045.0, 'Distance': 300.0}\n",
            "Status: 200 | Uploaded: {'Temperature': 26.2, 'Humidity': 31.5, 'Pressure': 978.0, 'Distance': 190.0}\n",
            "Status: 200 | Uploaded: {'Temperature': 33.3, 'Humidity': 85.0, 'Pressure': 941.0, 'Distance': 199.9}\n",
            "Status: 200 | Uploaded: {'Temperature': 24.6, 'Humidity': 27.9, 'Pressure': 938.5, 'Distance': 180.0}\n",
            "Status: 200 | Uploaded: {'Temperature': 31.0, 'Humidity': 65.0, 'Pressure': 970.2, 'Distance': 15.0}\n",
            "Outdoor Sensor Data:\n",
            "Status: 200 | Uploaded: {'Temperature': 27.3, 'Humidity': 65.2, 'Dlight': 8500}\n",
            "Status: 200 | Uploaded: {'Temperature': 41.2, 'Humidity': 78.5, 'Dlight': 12000}\n",
            "Status: 200 | Uploaded: {'Temperature': 50.1, 'Humidity': 82.3, 'Dlight': 9800}\n",
            "Status: 200 | Uploaded: {'Temperature': 19.8, 'Humidity': 55.1, 'Dlight': 450}\n",
            "Status: 200 | Uploaded: {'Temperature': 38.6, 'Humidity': 79.9, 'Dlight': 7300}\n",
            "Status: 200 | Uploaded: {'Temperature': 44.4, 'Humidity': 81.0, 'Dlight': 6500}\n",
            "Status: 200 | Uploaded: {'Temperature': -1.2, 'Humidity': 63.4, 'Dlight': 200}\n",
            "Status: 200 | Uploaded: {'Temperature': 0.0, 'Humidity': 70.2, 'Dlight': 500}\n",
            "Status: 200 | Uploaded: {'Temperature': 31.0, 'Humidity': 85.0, 'Dlight': 9100}\n",
            "Status: 200 | Uploaded: {'Temperature': 48.8, 'Humidity': 74.0, 'Dlight': 13000}\n",
            "Status: 200 | Uploaded: {'Temperature': 35.6, 'Humidity': 60.6, 'Dlight': 10200}\n",
            "Status: 200 | Uploaded: {'Temperature': 40.1, 'Humidity': 80.1, 'Dlight': 10800}\n",
            "Status: 200 | Uploaded: {'Temperature': 50.0, 'Humidity': 77.7, 'Dlight': 9900}\n",
            "Status: 200 | Uploaded: {'Temperature': 45.3, 'Humidity': 88.0, 'Dlight': 8700}\n",
            "Status: 200 | Uploaded: {'Temperature': 32.5, 'Humidity': 64.0, 'Dlight': 300}\n",
            "Status: 200 | Uploaded: {'Temperature': 29.4, 'Humidity': 82.5, 'Dlight': 1400}\n",
            "Status: 200 | Uploaded: {'Temperature': 42.2, 'Humidity': 90.1, 'Dlight': 250}\n",
            "Status: 200 | Uploaded: {'Temperature': 30.0, 'Humidity': 79.8, 'Dlight': 10000}\n",
            "Status: 200 | Uploaded: {'Temperature': 49.0, 'Humidity': 81.9, 'Dlight': 11500}\n",
            "Status: 200 | Uploaded: {'Temperature': -3.5, 'Humidity': 67.2, 'Dlight': 5}\n"
          ]
        }
      ],
      "source": [
        "# Navigate to project folder and ensure we're on the 'develop' branch\n",
        "import os, subprocess, sys\n",
        "\n",
        "REPO_DIR = \"/content/Cloud_Computing\"\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    subprocess.run([\n",
        "        \"git\", \"clone\", \"-b\", \"develop\",\n",
        "        \"https://github.com/Method-for-Software-System-Development/Cloud_Computing.git\",\n",
        "        REPO_DIR\n",
        "    ], check=True)\n",
        "\n",
        "# Update & checkout develop if repo already exists\n",
        "subprocess.run([\"git\", \"-C\", REPO_DIR, \"fetch\", \"origin\"], check=True)\n",
        "subprocess.run([\"git\", \"-C\", REPO_DIR, \"checkout\", \"develop\"], check=True)\n",
        "subprocess.run([\"git\", \"-C\", REPO_DIR, \"pull\"], check=True)\n",
        "\n",
        "# Install importnb (only needed once per session)\n",
        "%pip install importnb --quiet\n",
        "\n",
        "# Add firebase folder to Python path and import its notebook as module\n",
        "sys.path.append(os.path.join(REPO_DIR, \"firebase\"))  # for FireBase.ipynb\n",
        "sys.path.append(REPO_DIR)                            # for FAULT_RULES.ipynb\n",
        "from importnb import Notebook\n",
        "\n",
        "with Notebook():\n",
        "    import FireBase as fb                           # now fb.add_user, fb.get_user, etc. are available\n",
        "\n",
        "\n",
        "firebase_url = fb.firebase_url"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java and Spark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark pyspark\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "# Initialize Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Firebase Big Data Analysis\").getOrCreate()"
      ],
      "metadata": {
        "id": "8VxV5xiLAzuj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEYlGv9kE59n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}