{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY0Lc4PLRcdES4g5LLoPXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Method-for-Software-System-Development/Cloud_Computing/blob/develop/logic/chatbot_controller.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Imports ----\n",
        "import time\n",
        "import difflib\n",
        "from datetime import datetime\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load other project modules using importnb\n",
        "from importnb import Notebook\n",
        "with Notebook():\n",
        "    import mqqt_sim_indoor as indoor\n",
        "    import mqqt_sim_outdoor as outdoor\n",
        "    import user_controller as uc\n",
        "    import FireBase as fb\n",
        "\n",
        "# Gemini API key (ensure this is set in your Colab secrets)\n",
        "GEMINI_API_KEY = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "7hy9NPq-cCoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sensor Meta Table\n",
        "-----------------\n",
        "Defines metadata for all sensors in the OptiLine system.\n",
        "This information is used to answer questions about sensor functions, valid value ranges, and sensor descriptions.\n",
        "\"\"\"\n",
        "\n",
        "SENSORS_META = {\n",
        "    \"temperature\": {\n",
        "        \"label\": \"Temperature\",\n",
        "        \"units\": \"°C\",\n",
        "        \"locations\": [\"indoor\", \"outdoor\"],\n",
        "        \"description\": \"Measures ambient air temperature.\",\n",
        "        \"normal_range\": [18, 26],\n",
        "        \"details\": \"Temperature sensors are used to monitor the climate in the production environment and ensure optimal conditions.\"\n",
        "    },\n",
        "    \"humidity\": {\n",
        "        \"label\": \"Humidity\",\n",
        "        \"units\": \"%\",\n",
        "        \"locations\": [\"indoor\", \"outdoor\"],\n",
        "        \"description\": \"Measures relative air humidity.\",\n",
        "        \"normal_range\": [30, 60],\n",
        "        \"details\": \"Humidity sensors help prevent issues such as condensation, corrosion, or material degradation.\"\n",
        "    },\n",
        "    \"pressure\": {\n",
        "        \"label\": \"Pressure\",\n",
        "        \"units\": \"hPa\",\n",
        "        \"locations\": [\"indoor\"],\n",
        "        \"description\": \"Measures atmospheric pressure.\",\n",
        "        \"normal_range\": [1000, 1025],\n",
        "        \"details\": \"Pressure sensors provide data that can be used for weather analysis or to ensure safety standards in the facility.\"\n",
        "    },\n",
        "    \"dlight\": {\n",
        "        \"label\": \"Dlight\",\n",
        "        \"units\": \"Lux\",\n",
        "        \"locations\": [\"outdoor\"],\n",
        "        \"description\": \"Measures light intensity (illuminance).\",\n",
        "        \"normal_range\": [10000, 50000],\n",
        "        \"details\": \"Dlight sensors can be used to monitor daylight exposure, useful for environmental analysis.\"\n",
        "    },\n",
        "    \"distance\": {\n",
        "        \"label\": \"Distance\",\n",
        "        \"units\": \"mm\",\n",
        "        \"locations\": [\"indoor\"],\n",
        "        \"description\": \"Ultrasonic sensor detects distance changes (e.g., movement nearby).\",\n",
        "        \"normal_range\": [0, 500],\n",
        "        \"details\": \"Distance sensors are used for safety, automation, and detecting human or object presence.\"\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "ww-rJ9kRcQGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "User Guide, FAQ, and System Context\n",
        "-----------------------------------\n",
        "This context is included in every prompt to Gemini, providing the model with up-to-date knowledge about the OptiLine Dashboard,\n",
        "the CIM & Robotics Laboratory, available sensors, and operational policies.\n",
        "\"\"\"\n",
        "\n",
        "OPTI_BOT_CONTEXT = \"\"\"\n",
        "Welcome to the OptiLine Dashboard – a real-time cloud-based interface for engineers in the CIM & Robotics Lab.\n",
        "\n",
        "Main Features:\n",
        "• Live Sensors Dashboard – Monitor real-time data from indoor and outdoor sensors.\n",
        "• Statistics Panel – Analyze historical sensor data with interactive plots.\n",
        "• MQTT Search Engine – Search technical documentation from MQTT.org.\n",
        "• Fault Simulator – Practice troubleshooting simulated malfunctions.\n",
        "• User Directory – View contact information for system users.\n",
        "• Leaderboard – Track your performance points relative to other engineers.\n",
        "\n",
        "Available Sensors:\n",
        "- Temperature (°C): Measures ambient temperature (indoor & outdoor)\n",
        "- Humidity (%): Measures relative humidity (indoor & outdoor)\n",
        "- Pressure (hPa): Measures atmospheric pressure (indoor)\n",
        "- Dlight (Lux): Measures light intensity (outdoor)\n",
        "- Distance (mm): Ultrasonic sensor for movement detection (indoor)\n",
        "All sensors stream data in real time via MQTT protocol.\n",
        "\n",
        "How to Earn Points:\n",
        "- Complete fault simulator challenges.\n",
        "- More complex faults award higher scores.\n",
        "- Time efficiency matters: faster repairs = better ranking.\n",
        "- You must complete all simulator steps for points; no partial credit.\n",
        "- Your total score determines your leaderboard rank.\n",
        "\n",
        "FAQ:\n",
        "Q: Can I skip steps in the Fault Simulator and still get points?\n",
        "A: No. You must complete all required steps before submitting. Partial credit is not available.\n",
        "\n",
        "Q: Can I view or repeat previous faults?\n",
        "A: Not at this stage. Handled faults cannot be revisited.\n",
        "\n",
        "Q: Are the sensors live or simulated?\n",
        "A: Both modes are supported. Simulation streams realistic data; live mode uses real sensors.\n",
        "\n",
        "Q: How often is the leaderboard updated?\n",
        "A: The leaderboard updates after each completed challenge.\n",
        "\n",
        "About the CIM & Robotics Laboratory:\n",
        "The CIM & Robotics Laboratory at Braude College of Engineering, established in 1997, offers hands-on experience in industrial robotics, automation, CNC machining, CAD/CAM tools, vision-based quality control, and PLCs. It bridges theory with real-world manufacturing skills.\n",
        "\n",
        "About the Application:\n",
        "OptiLine Dashboard is accessible from any device with secure login, supporting both live and simulated data. It provides engineers with real-time monitoring, analysis, troubleshooting, and a gamified performance experience.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "YeqGnz6Nb05d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Live Data Helper Functions\n",
        "--------------------------\n",
        "Provides access to real-time sensor readings and leaderboard data.\n",
        "All helper functions are documented and return data in a format suitable for inclusion in a Gemini prompt.\n",
        "\"\"\"\n",
        "\n",
        "def get_sensor_value(sensor_type: str, location: str, mode: str = \"simulation\"):\n",
        "    \"\"\"\n",
        "    Retrieves the latest value for a specified sensor type and location.\n",
        "\n",
        "    Args:\n",
        "        sensor_type (str): Type of sensor ('temperature', 'humidity', 'pressure', 'dlight', 'distance')\n",
        "        location (str): 'indoor' or 'outdoor'\n",
        "        mode (str): 'simulation' or 'mqtt' (default is 'simulation')\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'value': float or None,\n",
        "            'units': str,\n",
        "            'timestamp': str (current time, ISO format),\n",
        "            'error': str (if sensor or location not found)\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Sensor availability check\n",
        "    if sensor_type not in SENSORS_META:\n",
        "        return {'value': None, 'units': '', 'timestamp': '', 'error': f\"Sensor '{sensor_type}' not found.\"}\n",
        "    if location not in SENSORS_META[sensor_type]['locations']:\n",
        "        return {'value': None, 'units': '', 'timestamp': '', 'error': f\"Sensor '{sensor_type}' is not available in {location}.\"}\n",
        "\n",
        "    # Data source selection\n",
        "    sensor_data = None\n",
        "    try:\n",
        "        if location == \"indoor\":\n",
        "            data = next(indoor.get_live_data_stream(mode=mode))\n",
        "        elif location == \"outdoor\":\n",
        "            data = next(outdoor.get_live_data_stream(mode=mode))\n",
        "        else:\n",
        "            return {'value': None, 'units': '', 'timestamp': '', 'error': \"Invalid location.\"}\n",
        "        # Try matching by label/case-insensitive\n",
        "        for key in data.keys():\n",
        "            if key.lower() == sensor_type.lower():\n",
        "                sensor_data = data[key]\n",
        "                break\n",
        "    except Exception as e:\n",
        "        return {'value': None, 'units': '', 'timestamp': '', 'error': f\"Error retrieving sensor data: {e}\"}\n",
        "\n",
        "    # Return structure\n",
        "    if sensor_data is not None:\n",
        "        return {\n",
        "            'value': sensor_data,\n",
        "            'units': SENSORS_META[sensor_type]['units'],\n",
        "            'timestamp': datetime.now().isoformat(timespec=\"seconds\"),\n",
        "            'error': \"\"\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'value': None,\n",
        "            'units': SENSORS_META[sensor_type]['units'],\n",
        "            'timestamp': '',\n",
        "            'error': f\"No data found for sensor '{sensor_type}' at '{location}'.\"\n",
        "        }\n",
        "\n",
        "def get_leaderboard_snapshot(username: str = \"\"):\n",
        "    \"\"\"\n",
        "    Retrieves the leaderboard: top 5 users and the rank/score of a given user (if specified).\n",
        "\n",
        "    Args:\n",
        "        username (str): Username to highlight in the leaderboard (optional).\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'top5': list of (rank, username, score),\n",
        "            'user_rank': (rank, score) or None\n",
        "        }\n",
        "    \"\"\"\n",
        "    try:\n",
        "        top5, user_info = uc.get_leaderboard(username)\n",
        "        return {\n",
        "            \"top5\": top5,\n",
        "            \"user_rank\": user_info  # (rank, score) tuple or None\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"top5\": [],\n",
        "            \"user_rank\": None,\n",
        "            \"error\": f\"Leaderboard error: {e}\"\n",
        "        }\n"
      ],
      "metadata": {
        "id": "fWNejF_dcT7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Smart Intent Detection & Data Injection\n",
        "---------------------------------------\n",
        "This cell improves question handling for sensor values, normal ranges, and sensor descriptions.\n",
        "It detects various user phrasings, including typos and synonyms, and injects the correct data into the Gemini prompt.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def detect_sensor_intent(message: str):\n",
        "    \"\"\"\n",
        "    Detects if the message requests a live sensor value, the normal range, or a description.\n",
        "    Returns a dict with intent type and extracted info.\n",
        "    \"\"\"\n",
        "    msg = message.lower()\n",
        "    # Simple typo handling: 'temprature', 'humditty', etc.\n",
        "    typo_map = {\n",
        "        \"temprature\": \"temperature\",\n",
        "        \"temperture\": \"temperature\",\n",
        "        \"temp\": \"temperature\",\n",
        "        \"humditty\": \"humidity\",\n",
        "        \"humdity\": \"humidity\",\n",
        "        \"presure\": \"pressure\",\n",
        "        \"d-light\": \"dlight\",\n",
        "        \"distanc\": \"distance\"\n",
        "    }\n",
        "    # Replace common typos in the message\n",
        "    for typo, correct in typo_map.items():\n",
        "        msg = msg.replace(typo, correct)\n",
        "\n",
        "    # Sensor & location detection\n",
        "    sensor_types = list(SENSORS_META.keys())\n",
        "    locations = [\"indoor\", \"outdoor\"]\n",
        "    found_sensor, found_location = None, None\n",
        "    for s in sensor_types:\n",
        "        if s in msg:\n",
        "            found_sensor = s\n",
        "            break\n",
        "    for loc in locations:\n",
        "        if loc in msg:\n",
        "            found_location = loc\n",
        "            break\n",
        "    # Default location: prefer outdoor if available, else indoor\n",
        "    if found_sensor and not found_location:\n",
        "        if \"outdoor\" in SENSORS_META[found_sensor][\"locations\"]:\n",
        "            found_location = \"outdoor\"\n",
        "        else:\n",
        "            found_location = \"indoor\"\n",
        "\n",
        "    # --- Intent detection ---\n",
        "    # 1. Live value (What is the X, show me the X, current X, etc.)\n",
        "    if found_sensor and (\n",
        "        re.search(r\"(what is|show|current|get|value|reading|display)\\s.*\" + found_sensor, msg)\n",
        "        or msg.strip() == found_sensor\n",
        "    ):\n",
        "        return {\"intent\": \"live_value\", \"sensor\": found_sensor, \"location\": found_location}\n",
        "    # 2. Normal range (range, normal, valid, acceptable, safe, expected)\n",
        "    if found_sensor and re.search(r\"(range|normal|valid|acceptable|safe|expected)\", msg):\n",
        "        return {\"intent\": \"normal_range\", \"sensor\": found_sensor}\n",
        "    # 3. Sensor description/explanation (what does X do, explain, why, purpose)\n",
        "    if found_sensor and re.search(r\"(what does|explain|purpose|why|used for|function)\", msg):\n",
        "        return {\"intent\": \"sensor_description\", \"sensor\": found_sensor}\n",
        "    # Not detected\n",
        "    return {\"intent\": None}\n",
        "\n",
        "def enrich_prompt_with_sensor_data(intent_info, sensor_mode=\"simulation\"):\n",
        "    \"\"\"\n",
        "    Given detected intent, returns a string to inject to the Gemini prompt (live value, range, or description).\n",
        "    \"\"\"\n",
        "    if not intent_info or not intent_info.get(\"sensor\"):\n",
        "        return \"\"\n",
        "    sensor = intent_info[\"sensor\"]\n",
        "    if intent_info[\"intent\"] == \"live_value\" and intent_info.get(\"location\"):\n",
        "        data = get_sensor_value(sensor, intent_info[\"location\"], mode=sensor_mode)\n",
        "        if data[\"error\"]:\n",
        "            return data[\"error\"]\n",
        "        return (\n",
        "            f\"Current value of {intent_info['location']} {sensor}: \"\n",
        "            f\"{data['value']} {data['units']} (as of {data['timestamp']}).\"\n",
        "        )\n",
        "    elif intent_info[\"intent\"] == \"normal_range\":\n",
        "        rng = SENSORS_META[sensor][\"normal_range\"]\n",
        "        units = SENSORS_META[sensor][\"units\"]\n",
        "        return f\"The normal range for {sensor} is {rng[0]} to {rng[1]} {units}.\"\n",
        "    elif intent_info[\"intent\"] == \"sensor_description\":\n",
        "        desc = SENSORS_META[sensor][\"description\"]\n",
        "        details = SENSORS_META[sensor][\"details\"]\n",
        "        return f\"{desc} {details}\"\n",
        "    return \"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "4vue2ACngaSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Extended Intent Detection & Data Injection\n",
        "-----------------------------------------\n",
        "Detects user questions about the leaderboard (score, rank), active faults, and FAQ.\n",
        "Injects the relevant data into the Gemini prompt.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def detect_leaderboard_intent(message: str):\n",
        "    \"\"\"\n",
        "    Detects if the message requests leaderboard info, score, or rank for a user.\n",
        "    Returns dict with intent type and username if found.\n",
        "    \"\"\"\n",
        "    msg = message.lower()\n",
        "    # Common leaderboard/score words\n",
        "    keywords = [\"leaderboard\", \"score\", \"rank\", \"top\", \"points\", \"standing\", \"place\", \"position\"]\n",
        "    if any(k in msg for k in keywords):\n",
        "        # Try to extract username (simple: after 'of', 'for', '@', etc.)\n",
        "        username = \"\"\n",
        "        user_search = re.search(r\"(user ?name|of|for|@)\\s*(\\w+)\", msg)\n",
        "        if user_search:\n",
        "            username = user_search.group(2)\n",
        "        return {\"intent\": \"leaderboard\", \"username\": username}\n",
        "    return {\"intent\": None}\n",
        "\n",
        "def enrich_prompt_with_leaderboard(intent_info):\n",
        "    \"\"\"\n",
        "    Enriches the Gemini prompt with leaderboard data:\n",
        "    - Includes the current top 5 users (username + score).\n",
        "    - If a specific username is provided (e.g. in \"What is the score/rank of X?\"),\n",
        "      includes their rank and score even if they are not in the top 5.\n",
        "\n",
        "    Args:\n",
        "        intent_info (dict): Must contain 'intent' == \"leaderboard\" and optionally 'username'.\n",
        "\n",
        "    Returns:\n",
        "        str: English summary of leaderboard state for the prompt.\n",
        "    \"\"\"\n",
        "    if not intent_info or intent_info[\"intent\"] != \"leaderboard\":\n",
        "        return \"\"\n",
        "    username = intent_info.get(\"username\", \"\")\n",
        "    board = get_leaderboard_snapshot(username)\n",
        "    if \"error\" in board:\n",
        "        return board[\"error\"]\n",
        "\n",
        "    # Build top 5 table\n",
        "    table = \", \".join([f\"{rank}. {name} ({score})\" for rank, name, score in board[\"top5\"]])\n",
        "\n",
        "    user_rank = \"\"\n",
        "    ur = board.get(\"user_rank\")\n",
        "    # If user_rank is tuple (rank, score), show details if not in top 5\n",
        "    if ur and isinstance(ur, (tuple, list)) and len(ur) == 2:\n",
        "        rank, score = ur\n",
        "        in_top5 = any(name == username for _, name, _ in board[\"top5\"])\n",
        "        if not in_top5:\n",
        "            user_rank = f\"User '{username}' is ranked {rank} with {score} points.\"\n",
        "    elif username:\n",
        "        user_rank = f\"User '{username}' not found in the leaderboard.\"\n",
        "    return f\"Leaderboard (top 5): {table}. {user_rank}\"\n",
        "\n",
        "\n",
        "\n",
        "def detect_faults_intent(message: str):\n",
        "    \"\"\"\n",
        "    Detects if the message requests info about faults/errors in the system.\n",
        "    Returns dict with intent type.\n",
        "    \"\"\"\n",
        "    msg = message.lower()\n",
        "    if any(k in msg for k in [\"fault\", \"error\", \"malfunction\", \"problem\"]):\n",
        "        return {\"intent\": \"faults\"}\n",
        "    return {\"intent\": None}\n",
        "\n",
        "def enrich_prompt_with_faults(intent_info):\n",
        "    \"\"\"\n",
        "    Injects faults info into prompt.\n",
        "    \"\"\"\n",
        "    if not intent_info or intent_info[\"intent\"] != \"faults\":\n",
        "        return \"\"\n",
        "    try:\n",
        "        faults = fb.get_active_faults()\n",
        "        num_faults = len(faults) if faults else 0\n",
        "        return (\n",
        "            f\"There are currently {num_faults} active faults in the system.\"\n",
        "            if num_faults else \"No active faults found at the moment.\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return f\"Could not retrieve fault data: {e}\"\n",
        "\n",
        "def detect_faq_intent(message: str):\n",
        "    \"\"\"\n",
        "    Detects if the message matches a known FAQ/guide question (simplified).\n",
        "    Returns dict with intent type and matched question.\n",
        "    \"\"\"\n",
        "    msg = message.lower()\n",
        "    faq_qas = [\n",
        "        (\"can i skip steps\", \"No, you must complete all required steps before submitting. Partial credit is not available.\"),\n",
        "        (\"how do i earn points\", \"You earn points by completing Fault Simulator challenges. More difficult faults and faster completion earn more points.\"),\n",
        "        (\"are the sensors live\", \"The system supports both live and simulated sensor data.\"),\n",
        "        (\"how often does the leaderboard update\", \"The leaderboard updates after each completed challenge.\"),\n",
        "        (\"what is the fault simulator\", \"The Fault Simulator lets you practice troubleshooting simulated malfunctions for points.\"),\n",
        "        (\"about the cim & robotics lab\", \"The CIM & Robotics Lab at Braude College provides hands-on experience in industrial robotics and automation.\")\n",
        "    ]\n",
        "    for q, a in faq_qas:\n",
        "        if q in msg:\n",
        "            return {\"intent\": \"faq\", \"answer\": a}\n",
        "    return {\"intent\": None}\n",
        "\n",
        "def enrich_prompt_with_faq(intent_info):\n",
        "    \"\"\"\n",
        "    Injects FAQ answer into prompt.\n",
        "    \"\"\"\n",
        "    if intent_info and intent_info[\"intent\"] == \"faq\":\n",
        "        return intent_info[\"answer\"]\n",
        "    return \"\"\n"
      ],
      "metadata": {
        "id": "QE0jb0NihIpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Improved Main Entry: ask_optibot (with smart intent detection)\n",
        "-------------------------------------------------------------\n",
        "Handles user questions using all smart intent/enrichment functions before calling Gemini.\n",
        "Injects live values, normal ranges, leaderboard data, faults, and FAQ answers into the prompt as needed.\n",
        "\"\"\"\n",
        "\n",
        "def ask_optibot(message: str, chat_history: list, sensor_mode: str = \"simulation\") -> tuple:\n",
        "    \"\"\"\n",
        "    Main entry point for OptiBot Q&A (improved version).\n",
        "\n",
        "    Args:\n",
        "        message (str): User's latest message (question), in English.\n",
        "        chat_history (list): List of previous messages: {\"role\": \"user\"/\"assistant\", \"content\": str}\n",
        "        sensor_mode (str): 'simulation' or 'mqtt' (default: simulation)\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - Empty string (to clear Gradio input)\n",
        "            - Updated chat_history (with the new user message and the bot response)\n",
        "    \"\"\"\n",
        "    if chat_history is None:\n",
        "        chat_history = []\n",
        "\n",
        "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "    enrichment_notes = []\n",
        "\n",
        "    # 1. Sensor intent\n",
        "    sensor_intent = detect_sensor_intent(message)\n",
        "    enrichment_notes.append(enrich_prompt_with_sensor_data(sensor_intent, sensor_mode))\n",
        "\n",
        "    # 2. Leaderboard intent\n",
        "    leaderboard_intent = detect_leaderboard_intent(message)\n",
        "    enrichment_notes.append(enrich_prompt_with_leaderboard(leaderboard_intent))\n",
        "\n",
        "    # 3. Faults intent\n",
        "    faults_intent = detect_faults_intent(message)\n",
        "    enrichment_notes.append(enrich_prompt_with_faults(faults_intent))\n",
        "\n",
        "    # 4. FAQ intent\n",
        "    faq_intent = detect_faq_intent(message)\n",
        "    enrichment_notes.append(enrich_prompt_with_faq(faq_intent))\n",
        "\n",
        "    # Filter out empty notes\n",
        "    enrichment_notes = [n for n in enrichment_notes if n]\n",
        "\n",
        "    # ---- Build prompt with highlighted enrichment ----\n",
        "    prompt = OPTI_BOT_CONTEXT.strip() + \"\\n\\n\"\n",
        "    prompt += (\n",
        "        \"When answering, ALWAYS use the data in the section 'Relevant live system data' below if it exists. \"\n",
        "        \"If the answer is not available below, use your general world knowledge to answer. \"\n",
        "        \"When a user's rank is provided, mention both the rank and score in your answer.\\n\"\n",
        "    )\n",
        "    if enrichment_notes:\n",
        "        prompt += \"\\n===== Relevant live system data =====\\n\"\n",
        "        prompt += \"\\n\".join(enrichment_notes)\n",
        "        prompt += \"\\n====================================\\n\"\n",
        "    prompt += f\"\\nUser question: {message}\\n\"\n",
        "\n",
        "    # Call Gemini API\n",
        "    try:\n",
        "        if not GEMINI_API_KEY:\n",
        "            bot_response = \"Error: Gemini API key is missing. Please contact your administrator.\"\n",
        "        else:\n",
        "            genai.configure(api_key=GEMINI_API_KEY)\n",
        "            model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "            response = model.generate_content(prompt)\n",
        "            bot_response = response.text.strip() if hasattr(response, \"text\") else str(response)\n",
        "    except Exception as ex:\n",
        "        bot_response = (\n",
        "            \"Sorry, I could not process your question due to a system error: \"\n",
        "            f\"{ex}\"\n",
        "        )\n",
        "\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
        "    return \"\", chat_history\n"
      ],
      "metadata": {
        "id": "GI0DLKftcxfm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}